# Genesis Integration Guide - ADR Prompt Tuning Infrastructure

**Purpose**: Bootstrap new projects with the ADR prompt tuning infrastructure without modifications.

---

## What Gets Deployed

The ADR prompt tuning system includes:

### Core Tools
```
tools/
â”œâ”€â”€ adr-scorer.js           (426 lines) - Objective ADR quality scoring engine
â”œâ”€â”€ prompt-tuner.js         (400+ lines) - Test runner & improvement suggester
â””â”€â”€ lib/
    â””â”€â”€ common.sh           - Shared bash utilities
```

### Prompts (Ready for Production)
```
prompts/
â”œâ”€â”€ phase1.md               - Initial ADR generation (Claude prompt)
â”œâ”€â”€ phase2.md               - Critical review (Gemini prompt)
â””â”€â”€ phase3.md               - Final synthesis (Claude prompt)
```

### Test Cases (For Validation)
```
tools/
â””â”€â”€ test-cases/
    â”œâ”€â”€ test_001.json       - Microservices migration
    â”œâ”€â”€ test_002.json       - Framework migration
    â”œâ”€â”€ test_003.json       - Database selection
    â”œâ”€â”€ test_004.json       - Authentication strategy
    â””â”€â”€ test_005.json       - API versioning
```

### Documentation
```
Documentation Files (Deploy As-Is):
â”œâ”€â”€ VALIDATION_RESULTS.md           - Baseline scores & results
â”œâ”€â”€ USAGE_EXAMPLES.md               - Production examples
â”œâ”€â”€ API_INTEGRATION_GUIDE.md         - Integration instructions
â”œâ”€â”€ TROUBLESHOOTING.md              - Debug & fix guide
â””â”€â”€ PROMPT_TUNING.md                - Original detailed guide
```

---

## Deployment Checklist

### Pre-Deployment Validation

```bash
# 1. Verify all tools executable
node tools/prompt-tuner.js test phase1 --mock
node tools/prompt-tuner.js test phase2 --mock
node tools/prompt-tuner.js test phase3 --mock

# Expected: All phases score 3.9+/5.0

# 2. Verify linting passes
npm run lint

# Expected: 0 errors, 0 warnings

# 3. Verify test suite passes
npm test

# Expected: All tests pass

# 4. Verify documentation complete
ls -la VALIDATION_RESULTS.md USAGE_EXAMPLES.md API_INTEGRATION_GUIDE.md TROUBLESHOOTING.md

# Expected: All files exist and contain substantive content
```

### Files to Include

**Copy these files EXACTLY as-is**:

```
âœ… tools/adr-scorer.js                    - No changes
âœ… tools/prompt-tuner.js                  - No changes
âœ… prompts/phase1.md                      - No changes
âœ… prompts/phase2.md                      - No changes
âœ… prompts/phase3.md                      - No changes
âœ… VALIDATION_RESULTS.md                  - Include baseline scores
âœ… USAGE_EXAMPLES.md                      - Production reference
âœ… API_INTEGRATION_GUIDE.md                - Integration guide
âœ… TROUBLESHOOTING.md                     - Debug reference
âœ… tools/test-cases/*.json               - 5 test cases
```

### Files to Skip

```
âŒ node_modules/                          - Installed via npm
âŒ coverage/                               - Generated by npm test
âŒ prompt_tuning_results_*/               - Generated by tooling
âŒ .env                                    - Contains API keys (use .env.example instead)
âŒ SESSION_CHECKPOINT.md                  - Temporary session file
âŒ *_SUMMARY.md                           - Session summaries (archive as needed)
```

---

## Integration Steps

### Step 1: Copy Core Files
```bash
# Assuming you're bootstrapping a new project with Genesis
mkdir -p tools prompts
cp architecture-decision-record/tools/adr-scorer.js tools/
cp architecture-decision-record/tools/prompt-tuner.js tools/
cp architecture-decision-record/prompts/*.md prompts/
```

### Step 2: Verify Setup
```bash
# Test that tools work
node tools/prompt-tuner.js test phase1 --mock

# Expected output:
# ğŸ§ª Testing Phase PHASE1 Prompts
# âœ… Phase phase1 Average Score: 4.02/5.0
```

### Step 3: Add Documentation
```bash
# Copy all documentation
cp architecture-decision-record/VALIDATION_RESULTS.md .
cp architecture-decision-record/USAGE_EXAMPLES.md .
cp architecture-decision-record/API_INTEGRATION_GUIDE.md .
cp architecture-decision-record/TROUBLESHOOTING.md .
```

### Step 4: Update Package.json
Add these scripts to `package.json`:

```json
{
  "scripts": {
    "adr:phase1": "node tools/prompt-tuner.js test phase1 --mock",
    "adr:phase2": "node tools/prompt-tuner.js test phase2 --mock",
    "adr:phase3": "node tools/prompt-tuner.js test phase3 --mock",
    "adr:test": "npm run adr:phase1 && npm run adr:phase2 && npm run adr:phase3",
    "adr:suggest": "node tools/prompt-tuner.js suggest-improvements phase1 && node tools/prompt-tuner.js suggest-improvements phase2 && node tools/prompt-tuner.js suggest-improvements phase3"
  }
}
```

### Step 5: Verify Deployment
```bash
# Run full test suite
npm run lint
npm test
npm run adr:test

# Expected:
# âœ“ Linting: 0 errors
# âœ“ Tests: all pass
# âœ“ Phase 1: 4.02/5.0
# âœ“ Phase 2: 3.96/5.0
# âœ“ Phase 3: 3.96/5.0
```

---

## Understanding the Baseline

### Current Quality Scores
```
Phase 1 - Initial ADR Draft
â”œâ”€â”€ Overall: 4.02/5.0 âœ…
â”œâ”€â”€ Completeness: 4.43/5.0 âœ…
â”œâ”€â”€ Clarity: 4.08/5.0 âš ï¸ (target: 4.3+)
â””â”€â”€ Consequences Balance: 4.20/5.0 âœ…

Phase 2 - Critical Review
â”œâ”€â”€ Overall: 3.96/5.0 âœ…
â”œâ”€â”€ Completeness: 4.43/5.0 âœ…
â”œâ”€â”€ Clarity: 4.16/5.0 âš ï¸ (framework decisions harder)
â””â”€â”€ Consequences Balance: 4.20/5.0 âœ…

Phase 3 - Final Synthesis
â”œâ”€â”€ Overall: 3.96/5.0 âœ…
â”œâ”€â”€ Completeness: 4.43/5.0 âœ…
â”œâ”€â”€ Clarity: 4.08/5.0 âš ï¸ (microservices harder to synthesize)
â””â”€â”€ Consequences Balance: 4.20/5.0 âœ…

Production Readiness: 80% of ADRs score 4.0+/5.0 âœ…
```

### What These Scores Mean

**âœ… 4.0+/5.0**: Ready for publication
- All required sections present
- Specific architectural patterns named
- Concrete consequences with measurable impacts
- Team factors explicitly addressed
- Alternatives comparison included
- Production teams can implement confidently

**âš ï¸ 3.5-3.9/5.0**: Near-ready, needs refinement
- Most sections strong, but clarity needs work
- May have generic language ("improve", "complexity")
- Team factors may be vague
- Requires one round of clarification edits

**âŒ <3.5/5.0**: Needs significant work
- Missing required sections
- Vague decision or consequences
- Generic language throughout
- Not ready for publication

---

## First Time Usage

### Quick Start
```bash
# 1. Verify tools work
npm run adr:test

# 2. Review usage examples
cat USAGE_EXAMPLES.md

# 3. Review baseline validation
cat VALIDATION_RESULTS.md

# 4. Start generating ADRs using API_INTEGRATION_GUIDE.md
```

### First ADR Generation
Use this process for your first ADR:

```bash
# 1. Prepare context
# - Current state: What do you have?
# - Problem: What's wrong?
# - Specific numbers: Growth %, deployment time, costs
# - Team: Size, skills, constraints

# 2. Run Phase 1 test to understand output format
npm run adr:phase1

# 3. Review USAGE_EXAMPLES.md to see what high-quality looks like

# 4. Use API_INTEGRATION_GUIDE.md to integrate with Claude/Gemini

# 5. If score < 4.0, consult TROUBLESHOOTING.md
```

---

## Customization (if needed)

### When to Customize Prompts

**Only customize if**:
1. You have 3+ ADRs scoring <3.9
2. Specific architectural pattern not covered by current prompts
3. Domain-specific language needed (for framework decisions, microservices, etc.)

**Never customize if**:
- Scores are 3.9+ (don't fix what's working)
- You're just starting (use baseline first)
- You haven't read TROUBLESHOOTING.md yet

### How to Customize Safely

```bash
# 1. Create a backup of current prompts
cp prompts/phase1.md prompts/phase1.md.backup
cp prompts/phase2.md prompts/phase2.md.backup
cp prompts/phase3.md prompts/phase3.md.backup

# 2. Make ONE change at a time
# Edit prompts/phase1.md - add one example or one requirement

# 3. Test immediately
npm run adr:phase1

# 4. If scores improved (or stayed same), keep the change
# If scores dropped, revert:
cp prompts/phase1.md.backup prompts/phase1.md

# 5. Only commit to repo if all tests pass
npm run lint && npm test && npm run adr:test
```

### Common Customizations

**For Framework Migration Decisions**:
Add to phase1.md:
```
### Framework Migration Clarity
- Name FROM framework (e.g., "Angular 1.x")
- Name TO framework (e.g., "React 18")
- Specify timeline (e.g., "6-month migration, 1 month per team")
- Name affected teams and component counts
```

**For Microservices Architecture**:
Add to phase1.md:
```
### Microservices Service Boundaries
- List specific services and their domains (e.g., "Orders", "Inventory")
- Specify data ownership (which tables each service owns)
- State deployment independence (each service separate CI/CD)
- Name deployment frequency improvement (e.g., "5 minutes vs. 45 minutes")
```

---

## Monitoring & Maintenance

### Weekly Health Check
```bash
# Run the full test suite
npm run adr:test

# Expected: All phases 3.9+/5.0

# If any phase drops below 3.9:
npm run adr:suggest
# Review suggestions and implement if needed
```

### Monthly Review
```bash
# Check if prompts need updates
node tools/prompt-tuner.js suggest-improvements phase1
node tools/prompt-tuner.js suggest-improvements phase2
node tools/prompt-tuner.js suggest-improvements phase3

# If suggestions indicate systematic gaps, consider updating prompts
```

### After Major Changes
```bash
# If you update prompts:
npm run lint
npm test
npm run adr:test

# All must pass before committing
```

---

## Troubleshooting Deployment

### Tools Not Executable
```bash
# Error: "command not found: node tools/prompt-tuner.js"

# Fix:
chmod +x tools/prompt-tuner.js
node tools/prompt-tuner.js test phase1 --mock
```

### Low Test Scores on First Run
```bash
# Scores below baseline (phase1 < 4.0)

# Likely cause: Missing test case files
ls -la tools/test-cases/
# Should see: test_001.json through test_005.json

# Fix: Copy test cases from source
cp architecture-decision-record/tools/test-cases/* tools/test-cases/
npm run adr:test
```

### API Integration Failing
```bash
# Error when calling Claude/Gemini APIs

# Fix:
# 1. Verify API keys are set (use .env, not hardcoded)
# 2. Test with mock data first: node tools/prompt-tuner.js test phase1 --mock
# 3. See API_INTEGRATION_GUIDE.md for token usage and rate limiting
```

---

## File Sizes (Reference)

```
tools/adr-scorer.js:     ~15 KB   (426 lines)
tools/prompt-tuner.js:   ~18 KB   (400+ lines)
prompts/phase1.md:       ~8 KB    (132 lines)
prompts/phase2.md:       ~7 KB    (107 lines)
prompts/phase3.md:       ~8 KB    (113 lines)

Total tools/prompts:     ~56 KB   (very small, quick to deploy)

Documentation:
VALIDATION_RESULTS.md:   ~12 KB
USAGE_EXAMPLES.md:       ~25 KB
API_INTEGRATION_GUIDE.md: ~18 KB
TROUBLESHOOTING.md:      ~16 KB

Total documentation:     ~71 KB   (reference only, not deployed to prod)
```

---

## Success Criteria

âœ… **Deployment successful if**:
1. All files copied without errors
2. `npm run lint` returns 0 errors
3. `npm test` passes all tests
4. `npm run adr:test` shows all phases 3.9+/5.0
5. Documentation accessible and readable

âœ… **Ready for production if**:
1. All above criteria met
2. API keys configured for Claude and Gemini
3. Test cases validated (at least 5 working)
4. Error handling implemented in API integration
5. Logging/monitoring configured

---

## Next Steps After Deployment

1. **Read USAGE_EXAMPLES.md** - Understand what high-quality ADRs look like
2. **Review API_INTEGRATION_GUIDE.md** - Implement API integration
3. **Generate your first ADR** - Test with a real architectural decision
4. **Monitor scores** - Track quality over time
5. **Customize if needed** - Only after scores stable and understanding baseline

---

## Contact & Support

**If system isn't working**:
1. Check TROUBLESHOOTING.md for common issues
2. Verify all files deployed: `ls -la tools/ prompts/`
3. Run diagnostics: `npm run adr:test && npm run adr:suggest`
4. Review VALIDATION_RESULTS.md for expected baseline
5. See API_INTEGRATION_GUIDE.md for detailed integration help

**For enhancement requests**:
- Document what you're trying to improve (e.g., "framework migration clarity")
- Share current ADR and scores
- Propose specific prompt change or example
- Test locally first with `npm run adr:test` after changes

---

**Version**: 1.0  
**Status**: Production-Ready for Genesis Bootstrap  
**Last Validated**: 2025-12-02  
**Test Coverage**: 5 end-to-end test cases covering all major architectural domains  
**Deployment Time**: <5 minutes  
**Post-Deployment Setup**: <15 minutes (API keys + one test ADR)
